<!DOCTYPE html>
<html lang="en">
<head>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
  <title>W3C Workshop on Smart Voice Agents</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="style.css">
  <meta name="twitter:site" content="@w3c">
  <meta name="twitter:card" content="summary_large_image">
</head>

<body>
<div id="banner-image">
  <h1>W3C Workshop on Smart Voice Agents</h1>
  <h2>@@Day@@ @@Month@@ 2025, virtual event</h2>
</div>

<main id="main" class="main">
<section id="home">
<p>This is a Call-for-Participation for the W3C Workshop on Smart Voice Agents.</p>
<p>The workshop is free, although you will need to email a brief proposal. Please see the <!-- a href="speakers.html"-->@@@information for speakers@@@<!-- /a--> for detail.</p>

<section>
<h2>General background</h2>
<ul>
<li>Even simpler applications with speech capability are getting more and more popular for ease of user interaction and richer user experience. Some of them are already available in our homes.</li>
<li>Voice agents are one of the essential applications on various devices, especially mobile phones, tablet devices, eBook readers, and gaming platforms. Moreover, the integration of speech capabilities into traditional platforms such as TVs, audio systems, and automobiles was a recent major technical advancement.</li>
</ul>
</section>

<section>
<h2>Focus</h2>
<ul>
<li>Firstly, see the current status of the voice-enabled smart platforms integrating multi-vendor services/applications/devices:
<ul>
  <li>Voice interaction with smart devices also in the Web of Things</li>
  <li>Control from Web browsers</li>
  <li>Interoperability and access to controls for accessibility/usability, e.g., smart cities</li>
</ul>
</li>
<li>Secondly, discuss the current situation in voice interaction technology for global deployment across all languages, including even nicer integration of LLMs to enhance natural language understanding and generation.</li>
<li>As a result, we would see and discuss the pain points, technological gaps, and then clarify potential impacts on the Web standards based on the pain points and gaps.</li>
</ul>
</section>

<section>
<h2>Possible topics</h2>
<p>The following list of possible topics is quite broad as a starting point and will actually be reduced depending on the interests of participants.</p>
<ul>
<li>Clarification of use cases of smart voice agents and their requirements</li>
<li>Summary of the current status:<ul>
<li>Overview of existing browser support and platforms, for example smart speakers and mobile phones</li>
<li>Integration of LLMs for voice interaction to enhance browser capabilities and platforms</li>
<li>Common interoperability issues for smart voice agents among browsers and platforms</li>
<li>State of the art of accuracy</li>
</ul>
</li>
<li>Needs of the users and developers of smart voice agents:<ul>
<li>User interfaces to smart voice agents, including accessibility/usability issues raised by smart agent technology</li>
<li>Internationalization and compatibility with region-specific technologies</li>
<li>Enhanced voice interaction with LLMs in the context of smart voice agents for improved usability, addressing issues such as:<ul>
<li>Hallucinations: LLMs may generate outputs that seem plausible but are factually incorrect.</li>
<li>Ambiguity in outputs: Inconsistent or vague responses can cause confusion in automated workflows.</li>
<li>Lack of accountability: Identifying the root cause of errors in an LLM’s predictions can be challenging.</li>
</ul>
</li>
<li>Managing input entities (sensors/applications) and output entities (actuators/devices/digital twins) from various vendors and their coordination.</li>
<li>Addressing presentation issues such as how, what, and when to transfer necessary information from input entities (users, devices, or applications) to output entities (users, devices, or applications).</li>
<li>Integrating multiple interchangeable modalities (typing, handwriting, voice, etc.).</li>
</ul>
</li>
<li>Horizontal platform considerations:<ul>
<li>Discovery of resources</li>
<li>Trust, privacy and security, for example tools such as encryption</li>
<li>Business aspects and the future of personal agents</li>
</ul>
</li>
<li>Demo of existing voice agents</li>
</ul>
</section>

<section>
<h2>Examples of related use cases</h2>
<p>The related technology area is broad, including:</p>
<ul>
<li>Voice agents and chatbots in various environments like smart homes, smart factories, smart cars, and smart cities</li>
<li>Smart speakers and smartphones as portals/user devices</li>
</ul>
<p>For example, Hybrid TV services (Web+TV integration based on HTML5, Second Screen, TTML, etc.) and smart home devices and services, possibly incorporating proprietary technology like MiniApps, can offer the following use cases:</p>
<ul>
<li>Asking the voice agent on the TV in the living room to order takeaway, e.g., &quot;I want to order a pizza.&quot;</li>
<li>Using voice commands to choose the food and saying &quot;checkout&quot; to the smartwatch to process the payment.</li>
</ul>
<p>Another example is searching for podcast or video content. The user can ask, &quot;Play [topic of a podcast or video],&quot; and the voice assistant will respond with, &quot;Here's what I found,&quot; while displaying search results on the smartphone display.
A useful user requirement may be the ability to request congruent user feedback (i.e., if voice is used for input, then speech is used for feedback).</p>
<blockquote>
<p><strong>NOTE:</strong> The above is just a few examples of the possible use cases, and the development of use cases and their requirements will be one topic of the workshop.</p>
</blockquote>
</section>

<section>
<h2>Who to attend?</h2>
<ul>
<li>Many possible stakeholders including:<ul>
<li>Service providers/System implementers</li>
<li>Government</li>
<li>Users and developers from various countries/communities</li>
<li>Standard organizations</li>
<li>Researchers from academia and industry</li>
</ul>
</li>
</ul>
</section>

<section>
<h2 id="pc">Program Committee</h2>
<p>You can send emails to the workshop Program Committee at: <a href="mailto:group-voiceagents-ws-pc@w3.org">group-voiceagents-ws-pc</a>.</p>

<h3>Chairs</h3>
<ul>
  <li>Deborah Dahl, Conversational Technologies</li>
  <li>Dirk Schnelle-Walka, Switch Consulting</li>
</ul>

<h3>Committee</h3>
<ul>
  <li>Deborah Dahl, Conversational Technologies</li>
  <li>Dirk Schnelle-Walka, Switch Consulting</li>
  <li>Gérard Chollet, CNRS</li>
  <li>Michael Koster, Dogtiger Labs</li>
  <li>Song Xu, China Mobile</li>
  <li>Brian Kardell, OpenJS Foundation</li>
  <li>Phill Archer, GS1</li>
  <li>Leonie Watson, TetraLogical</li>
  <li>Bev Corwin, Consultant</li>
  <li>Kaz Ashimura, W3C</li>
</ul>
</section>

</section>
</main>
<footer class="footer" id="footer">
    <p>
        W3C is proud to be an open and inclusive organization, focused on
        productive discussions and actions. Our <a href="https://www.w3.org/policies/code-of-conduct/">Code of Conduct</a> ensures that all voices can be heard. Questions? Contact Kaz Ashimura &lt;<a href="mailto:ashimura@w3.org">ashimura@w3.org</a>&gt;.
    </p>
    <p>
        Suggestions for improving this workshop page, such as fixing typos or
        adding specific topics, can be made by opening a <a href=
                                                                 "https://github.com/w3c/smartagents-workshop">pull request on GitHub</a>, or by
        emailing Kaz Ashimura &lt;<a href=
                                          "mailto:ashimura@w3.org">ashimura@w3.org</a>&gt;.
    </p>
</footer>
<script src="script.js"></script>
</body>
</html>
